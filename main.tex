
\documentclass[10pt]{article}

\input{macro}

\usepackage{titling}

\usepackage{times}

\usepackage{setspace}
%\doublespacing

\usepackage[multiple]{footmisc}

\setlength{\droptitle}{-5.5em} 

\setlength{\topmargin}{-.6in} 
\setlength{\textheight}{9in}
\setlength{\textwidth}{7in} 
\setlength{\headheight}{26pt}
\setlength{\headsep}{9pt} 
\setlength{\oddsidemargin}{-.26in}
\setlength{\evensidemargin}{.25in}

\renewcommand{\footnotesize}{\scriptsize}

\begin{document}

\title{Research Statement}
\author{Tanakorn Leesatapornwongsa}
\date{\vspace{-1ex} \small{Department of Computer Science, University of
Chicago}}

\maketitle

My research focuses on improving the dependability of cloud-scale distributed
systems such as distributed file systems, scale-out object stores, and
data-parallel frameworks. These distributed systems are back ends of many cloud
services, which the services are expected to be 24/7 dependable. Unfulfilled
dependability is costly; cloud service companies collectively lose billions of
dollars in revenue each year from service downtimes. To reach an ideal
dependability, it is very challenging because cloud back ends are complex. They
are written in millions of lines of code that are brittle and prone to failures.

The main focus of my dependability research is on the problem of
\textbf{\textit{distributed concurrency bugs (DC bugs)}}. DC bugs are caused by
nondeterministic orders of distributed events such as message arrivals,
hardware crashes/reboots, and network timeout. Cloud systems execute
multiple complicated distributed protocols concurrently (\eg, serving users'
requests, operating background tasks, and combined with untimely hardware
failures), and possible interleavings of the distributed events are beyond
developers' anticipation, which some interleavings might not be handled
properly, and can cause catastrophic failures such as data loss and downtimes.

Below I describe how I address the important and challenging problem of DC
bugs, specifically by (1) \textit{performing} an in-depth study of more than
100 real-world DC bugs and (2) \textit{advancing} the state of the art of model
checking for distributed systems. I also will describe my other work on
different aspects of cloud dependability rather than DC bugs.

\section{Distributed Concurrency Bugs (DC Bugs)}\label{dcbugs}

%To combat DC bugs, I establish my research in (1) \textbf{\textit{formal bug
%studies}} and (2) \textbf{\textit{distributed system model checking}}. 

\subsection{DC Bug Study \& Taxonomy} 

Bug and failure studies can significantly guide many aspects of dependability
research. Many researchers have recently employed formal studies on bugs and
failures. For example, a joint work between a VMWare engineer and academic
institutes studied bugs reported in open source projects and could point out an
urgency to address concurrency bugs in the Linux kernel.\footnote{Lin Tan, Chen
Liu, Zhenmin Li, Xuanhui Wang, Yuanyuan Zhou, and Chengxiang Zhai. Bug
characteristics in open source software. Empirical Software Engineering '14
19(6)}
%
There are also some studies on bugs in distributed systems\footnote{Sihan Li,
Hucheng Zhou, Haoxiang Lin, Tian Xiao, Haibo Lin, Wei Lin, and Tao Xie. A
Characteristic Study On Failures of Production Distributed Data-Parallel
Programs. ICSE '13}, however, I am not aware of any large-scale DC-bug studies
published. 

To fill the void, I, as one of the project leaders, created the
first largest taxonomy of 104 real-world DC bugs (named \taxdc)
\cite{Leesatapornwongsa+16-TaxDC} from four popular large-scale distributed
systems: Cassandra, HBase, Hadoop MapReduce/Yarn, and ZooKeeper.  \taxdc\
contains in-depth characteristics of DC bugs, stored in the form of 2,083
classification labels and 4,528 lines of re-enumerated steps to the bugs that
we manually added. We show that although DC bugs are complex, but they can be
abstracted and categorized with our taxonomy that covers all aspects of DC bugs
such as bug triggering, errors and failures, and bug fixing.

%\taxdc\ is the most comprehensive taxonomy that covers all aspects of DC bugs
%such as bug triggering, errors and failures, and bug fixing.

%Although DC bugs are complex, we can abstract and categorize them with our
%taxonomy that cover all aspects such as bug triggering, errors and failures, and
%bug fixing.
%
%\taxdc\ contains in-depth characteristics of DC bugs, stored in the form of 2083
%classification labels and 4528 lines of re-enumerated steps to the bugs that we
%manually added. Since we released \taxdc\ as a large-scale DC bugs benchmark,
%it has been downloaded from many research groups including academia and
%industries.

%Motivated by the availability of bug benchmarks for LC bugs, I release \taxdc\
%as a large-scale DC bugs benchmark.

With \taxdc, I can answer important questions such as: 
%
What are the root causes of DC bugs?
%
What are the inputs/triggering conditions? 
%
What errors/effects are caused by DC bugs?
%
How do developers fix DC bugs? 
%
By able to answer these questions, we made \textit{six} major findings that can
spur exciting research topics on DC bugs, for example, how to build fast model
checker that catch real-world DC bugs, how state-of-the-art
bug detection techniques applicable to DC bugs, how distributed systems
facilitate failure diagnosis, and how DC-bug-induced failure can be prevented at
runtime.
%
We release \taxdc\ as a large-scale DC-bug benchmark, and so far it has been
downloaded from more than \textit{twenty} research groups including academia and
industries. I believe \taxdc\ will help shape the future research on DC bugs.

%In addition to the taxonomy, we made six major findings that can 

%Are existing concurrency-bug-detection tools applicable for DC bugs? 
%The answers to these questions will guide my subsequent research projects.

\subsection{Distributed System Model Checking}

One powerful method for discovering hidden DC bugs is the use of an
\textit{implementation-level distributed system model checker} (\textbf{dmck}).
A dmck can discover buggy interleavings that lead to DC bugs by reordering
every possibility of nondeterministic distributed events. The last ten years
have seen a rise of dmcks such as 
%
MaceMC\footnote{Charles Killian, James Anderson, Ranjit Jhala,
and Amin Vahdat. Life, Death, and the Critical Transition: Finding Liveness Bugs
in Systems Code. NSDI '07}, 
%
\modist\footnote{Junfeng Yang, Tisheng Chen, Ming
Wu, Zhilei Xu, Xuezheng Liu, Haoxiang Lin, Mao Yang, Fan Long, Lintao Zhang, and
Lidong Zhou. MODIST: Transparent Model Checking of Unmodified Distributed
Systems. NSDI '09}, or Demeter.\footnote{Huayang Guo, Ming Wu, Lidong Zhou, Gang
Hu, Junfeng Yang, and Lintao Zhang. Practical Software Model Checking via
Dynamic Interface Reduction. SOSP '11} One big challenge faced by a dmck is the
state-space explosion problem (\ie, there are too many distributed events to
re-order). To address this, existing dmcks adopt a random walk or basic
reduction techniques such as dynamic partial order reduction (DPOR). Despite
these early successes, existing approaches cannot unearth many real-world DC
bugs, so I am advancing the state of the art of dmck to combat DC bugs, which I
describe below.

\subsubsection*{Semantic-Aware Model Checking (Initial Work)} 

I started my work by specifically addressing two limitations of existing dmcks.
First, existing dmcks treat every target system as a complete \textit{black
box}, and perform unnecessary reorderings of distributed events that would lead
to the same states (\ie, redundant executions). Second, they do not incorporate
complex multiple fault events (\eg, crashes, reboots, \etc) into their exploration
strategies, as such inclusion would exacerbate the state-space explosion
problem.

To address these limitations, I built Semantic-Aware Model Checking
(\textbf{SAMC})
\cite{Leesatapornwongsa+15-SamcIssta,Leesatapornwongsa+14-Samc}, a novel
white-box model checking approach that takes \textit{semantic knowledge} of how
distributed events (specifically, messages, crashes, and reboots) are processed
by the target system. The knowledge is fed from system developers and is
incorporated to create reduction policies.  The policies are based on sound
reduction techniques such as DPOR and symmetry, and they will tell SAMC not to
re-order some pairs of events such as message-message pairs, and message-crash
pairs, yet preserves soundness, because those cut out re-orderings are
redundant, and unnecessary to check.

I built SAMC from scratch with 10 KLOC, and I was able to reproduce 12 old bugs
in 3 cloud systems (Cassandra, Hadoop MapReduce, and ZooKeeper) involving
30-120 distributed events and multiple crashes and reboots. Some of these bugs
cannot be unearthed by non-SAMC approaches, even after two days. SAMC can find
the bugs up to 271x (33x on average) faster compared to state-of-the-art
techniques, it found two new bugs in Hadoop MapReduce and ZooKeeper, and there
were research groups and companies requested to adopt SAMC to test their
ongoing projects. An engineer from VMWare has contacted my advisor and
expressed his interest in SAMC for testing a product. In addition, although
SAMC was built for distributed systems, the principles of \textbf{semantic
awareness} I introduced are also applicable to multithreading software model
chekers as well.

\subsubsection*{Full Semantic-Aware Model Checking (Ongoing Work)} 

Although SAMC advances state of the art of dmcks to unearth DC bugs faster, but
I find that there are two major gaps between existing dmcks (including SAMC) and
real-world DC bugs. First, dmcks reorder messages by default, but they do not
control the timings of all events necessary for DC bugs. For example, MaceMC and
SAMC do not intercept local computation and do not exercise timeouts; \modist\
and Demeter do not inject multiple crash and reboot timings; and none of the
above include other faults such as untimely disk faults.
%
Second, controlling all necessary events is technically doable, but will
``\textit{blow up}'' the state space. Thus more innovations are needed to
devise fast exploration strategies that leverage semantic relationships among
all necessary events.

%that leverage semantic relationships among all necessary events.

To address the incompleteness of SAMC, I am building \fullcheck, a dmck that
intercepts all types of necessary events to unearth real-world DC bugs, but
will do so in a fast and scalable manner. Some dependability researchers
believe that black-box testing is not efficient for DC-bug testing, and using
semantic knowledge is an important future direction. I will build more powerful
semantic-awareness principles while adopting new reduction techniques in the
building of \fullcheck. \fullcheck\ will be the first dmck that controls all
distributed events necessary to catch DC bugs.

%There are many works from Microsoft on
%model checking for multithreading software to tackle state-space
%explosion\footnote{Madan Musuvathi, and Shaz Qadeer. Iterative Context Bounding
%for Systematic Testing of Multithreaded Programs. PLDI '07}\footnote{Katherine
%E. Coons, Madanlal Musuvathi, and Kathryn S. McKinley. Bounded Partial-Order
%Reduction. OOPSLA '13}, but there are not many works on dmcks, thus I am
%inventing more reduction techniques for dmcks in \fullcheck. 
%Techniques are also assisted by the incorporation of semantic relationships
%between the events. 

%More reduction techniques are needed, but the semantic-awareness is still the
%most important part. Demeter, the latest state of the art for exercising
%message-computation race, still hits a scalability wall, and the authors hint
%that using semantic knowledge is an important future direction. I will build
%more powerful semantic-awareness principles while adopting new reduction
%techniques in the building of \fullcheck. \fullcheck\ will be the first dmck
%that controls all distributed events necessary to catch DC bugs.

%For example, bounded model checking is a popular technique,
%which explores only limited depth of distributed events to avoid state-space
%explosion, could be useful for dmck, but integration must be done in a wise
%manner, because it works well for bugs hiding in early steps of execution only.
%Previous works from Microsoft showed that bounded model checking can work with
%LC-bug model checking effectively by introducing \textit{iterative context
%bounding} \footnote{Madan Musuvathi, and Shaz Qadeer. Iterative Context Bounding
%for Systematic Testing of Multithreaded Programs. PLDI '07} and \textit{bounded
%partial-order reduction} \footnote{Katherine E. Coons, Madanlal Musuvathi, and
%Kathryn S. McKinley. Bounded Partial-Order Reduction. OOPSLA '13}. For dmck, to
%effectively integrate bounded model checking, we need a subtle strategy to make
%sure that we still explore deep enough to reach hidden bugs.

%Demeter, the latest state of the art for exercising message-computation race,
%still hits a scalability wall and the authors hint that using semantic knowledge
%is an important future direction. To address the problem, I am building
%\fullcheck, a dmck that intercepts all necessary events to unearth real-world DC
%bugs, but will do so in a fast and scalable manner. I am inventing more powerful
%semantic-awareness principles while adopting new reduction techniques in the
%building of \fullcheck. \fullcheck\ will be the first dmck that
%controls all distributed events to unearth hidden DC bugs.

%\fullcheck\ will adopt more advanced reduction techniques assisted by
%the incorporation of semantic relationships between the events. 

% I could talk about other reduction technique here, maybe Demeter, bounded
% model checking from MSR, etc.

\subsection{Future Work}

\fullcheck\ will help developers unearth hidden DC bugs in a fast manner, but it
still requires manual efforts from developers to extract semantic knowledge and
feed to SAMC.
%
My future work will automate this semantic extracting process to reduce the
developers' burdensome, and I also plan to automate other manual efforts required
to test the systems as I explain next.

\subsubsection*{Automated Semantic Extractor}

So far, developers manually extract and incorporate the semantic knowledge to
SAMC. This process could introduce human errors and breaks soundness. Thus I
plan to advance SAMC to automatically extracts complete semantic knowledge into
reduction strategies with the help of program analysis. To do so, I adopt
symbolic execution to create the semantic-aware reduction policies. While others
have used symbolic execution with model checking for multithreading bugs, this
work will be the first case for dmck. 

\subsubsection*{Automatic Input Generator}

Execution paths to DC bugs often require complex input conditions such as
multiple faults, reboots, and protocol initiations. \taxdc\ shows 80\% of DC bugs
require more than one protocol, 35\% require multiple faults, and 29\% arise
because of interactions between foreground and background protocols. This again
highlights the complexity of complete systems. 
If developers do not test the systems with complex input conditions, the bugs
will not surface in a checking process. To address this complexity, I will adopt
static and dynamic analysis to generate the necessary input preconditions to
cover complex test scenarios necessary to catch hidden DC bugs.

\section{Other Work}

Other than DC bugs, I also address other dimensions of cloud dependability that
traditional dependability techniques are not enough to solve. I briefly explain
the other projects here.

%
%I joined a project
%performing the largest bugs study to find ``\textit{what bugs live in the
%cloud?}'' \cite{Gunawi+14-Cbs}.  We studied six popular Apache cloud
%infrastructures. We reviewed in total 21,399 submitted issues within 2011-2014,
%and perform a deep analysis of 3,655 ``\textit{vital}'' issues. This study show
%novel dimensions of bugs that are \textit{specific} to cloud systems only.
%Motivated by the discovery, I have been working in many projects to tackle the
%bugs in the cloud, which I explain below.

%\subsection*{Scalability Bugs}

\noindent
\textbf{Scalability Bug Checking}: Scalability bugs are latent bugs that are
scale-dependent; they only surface in large-scale deployments, but not in
small/medium-scale ones. Their presence jeopardizes systems reliability and
availability at scale. 
%
While others have tackled scalability bugs in data-plane protocols\footnote{Yang
Wang, Manos Kapritsos, Lara Schmidt, Lorenzo Alvisi, and Mike Dahlin.
Exalt: Empowering Researchers to Evaluate Large-Scale Storage Systems. NSDI
'14}, I found that scalability bugs can manifest in control protocols as well.
Control-protocol bugs are more disastrous, yet there is no work addresses about
them.
 
To address this problem, I started a pilot work on scalability checking
\cite{Gunawi+17-SCk-Insub,Leesatapornwongsa+17-SCk-InPrep}. I introduced \sck,
a methodology that enables developers to emulate systems at scale to check and
debug control protocols, which are CPU-intensive computing, on \textit{one
machine}. 
%
With \sck\ and just only one machine, I can reproduce six scalability bugs in
Cassandra, Riak, and Voldemort, which manifest in large scale only (\eg\
200-500 machines). 

%\subsection*{Cloud Bug Study}

\noindent
\textbf{Cloud Bug Study}: To build ground knowledge of holistic cloud
dependability, my colleagues and I performed the largest study on bugs in
cloud-scale distirbuted systems \cite{Gunawi+14-Cbs}. We studied six popular
cloud infrastructures including Cassandra, Flume, Hadoop MapReduce, HBase, HDFS,
and ZooKeeper, and reviewed in total 21,399 submitted issues within 2011-2014,
and performed a deep analysis of 3,655 ``\textit{vital}'' issues (\ie, real
issues affecting deployments). The study shows why cloud-scale distributed
systems are not dependable, and indicates novel dimensions of bugs that are
\textit{unique} to cloud systems such as scalability, topology, and
quality-of-services bugs. We released our cloud bug database to the public, and
so far it has been downloaded \textit{more than 100} times.

%Motivated by the discovery, I have been working in many
%projects to tackle the bugs in the cloud, which I explain below.

%\subsection*{Limpware Tolerant Computing}

\noindent
\textbf{Limpware Tolerant Computing}: It is well-known that hardware can fail in
different ways such as corruption, fail stop, and fail partial, but there is one
often-overlooked cause of performance instability:
``\textbf{limpware}'', \textit{limping} hardware whose performance
degrades significantly compared to its specification. There was no works
studied the impact of this overlooked limpware failure, so my colleagues and I
benchmarked five cloud systems (Cassandra, Hadoop, HBase, HDFS, and ZooKeeper)
with limpware injections \cite{Do+13-Limplock}. The result exposes the inability
of today's cloud systems in dealing with limpware. A single limpware can cripple
other healthy nodes, or even worse, a whole cluster. Motivated from this
observation, we introduced a Path-Based Speculative Execution
(\textbf{PBSE}), that helps data-parallel frameworks recover from limping
network interface cards \cite{Suminto+17-PBSE-InPrep}.

%\subsection*{Drill-Ready Cloud} 

\noindent
\textbf{Drill-Ready Cloud}: Faults in real deployments are very complex, and
the real deployment environments are arbitrary (multi datacenters, layers of
virtualization, massive workloads, \etc), but in offline testings, the
environments are much simpler, and the scale of the workloads and injected
faults are often orders of magnitude smaller. This makes offline testings
cannot catch complex bugs and cannot provide ideal dependability.  To reach
ideal dependability, I envision the future of cloud systems requires
\textit{online testing}, and introduced ``\textbf{failure
drill}'' \cite{Leesatapornwongsa+14-Drill-fixed}, the concepts of how online
testing for cloud should be operated.  The failure drill addresses how online
test can be safe, efficient, usable, and general.

\section{Summary}

I envision the future of cloud services to be ``\textit{uninterrupted}''. Cloud
services must be accessible anytime and anywhere, with fast and stable
performance, and not lose or corrupt users' data.
%
I am improving dependability of systems by addressing well-known unsolved
problem of DC bugs via model checker, and I am tackling new dimensions of cloud
dependability that the system community has not paid attention to such as
scalability and limpware tolerance.  A journey toward the goal is a long road,
but I believe my research advances system community toward the direction. 

\input{bib}

\end{document}
