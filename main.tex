
\documentclass[11pt]{article}

\input{macro}

\usepackage{titling}

\usepackage{times}

\usepackage{setspace}
%\doublespacing

\setlength{\droptitle}{-5.5em} 

\setlength{\topmargin}{-.6in} 
\setlength{\textheight}{9in}
\setlength{\textwidth}{7in} 
\setlength{\headheight}{26pt}
\setlength{\headsep}{9pt} 
\setlength{\oddsidemargin}{-.26in}
\setlength{\evensidemargin}{.25in}

\renewcommand{\footnotesize}{\scriptsize}

\begin{document}

\title{Research Statement}
\author{Tanakorn Leesatapornwongsa}
\date{\vspace{-1ex} \small{Department of Computer Science, University of
Chicago}}

\maketitle

My research focuses on improving the dependability of cloud-scale distributed
systems such as scale-out storage systems, distributed computing frameworks,
synchronization services, and cluster management services. Users demand 24/7
dependability of cloud computing systems so the systems must be reliable.  They
must be accessible anytime and anywhere, and not lose or corrupt users' data.
Unfulfilled dependability is costly. Internet service companies collectively
lose billions of dollars in revenue each year from service downtimes. Yet,
there are complex challenges to reach an ideal dependability.  Behind cloud
computing is a collection of hundreds of complex systems written in millions of
lines of code that are brittle and prone to failures.

I find that one unsolved reliability problem in cloud systems is
\textbf{\textit{distributed concurrency bugs (DC bugs)}}. DC bugs are caused by
non-deterministic order of distributed events such as message arrivals, faults,
and reboots. Cloud systems execute multiple complicated distributed protocols
concurrently (\eg, serving users' requests, operating some background tasks,
and combined with untimely hardware failures). The possible interleavings of
the distributed events are beyond developer's imaginations and some
interleavings might not be handled properly. The buggy distributed
interleavings can cause catastrophic failures such as data loss, data
inconsistencies and downtimes. 

Compared to the countless efforts in combating \textbf{\textit{local
concurrency bugs (LC bugs)}}, which occur due to non-determinism of thread
scheduling in multi-threaded software, DC bugs have not received the same
amount of attention.  I believe it is time for the dependability community to
address this important problem in a systematic and comprehensive manner. To
combat DC bugs, I establish my research in (1) \textbf{\textit{formal bug
studies}} and (2) \textbf{\textit{distributed system model checking}}. The
following sections explain my research in detail.

\section{Bug Study}

Bug or failure studies can significantly guide many aspects of dependability
research. Many dependability researchers have recently employed formal studies
on bugs and failures such as the studies on large-scale system bugs/failures
from Microsoft \footnote{Zhenyu Guo, Sean McDirmid, Mao Yang, Li Zhuang, Pu
Zhang, Yingwei Luo, Tom Bergan, Madan Musuvathi, Zheng Zhang, and Lidong Zhou.
Failure Recovery: When the Cure Is Worse Than the Disease. HotOS '13}
\footnote{Sihan Li, Hucheng Zhou, Haoxiang Lin, Tian Xiao, Haibo Lin, Wei Lin,
and Tao Xie. A Characteristic Study On Failures of Production Distributed
Data-Parallel Programs. ICSE '13}. These studies can identify opportunities for
new research, build taxonomies of new problems, or test new tools. I started my
research by doing formal bug study to gain foundations of combating DC bugs.

\subsection{Cloud Bug Study}

As an initiative, our group have performed the largest bugs study in six
important Apache cloud infrastructures including Cassandra, Flume, Hadoop
MapReduce, HBase, HDFS, and ZooKeeper \cite{Gunawi+14-Cbs}. We reviewed in
total 21,399 submitted issues within a three-year period (2011-2014) in Apache
bug repositories. We perform a deep analysis of 3,655 ``vital'' issues (\ie,
real issues affecting deployments) with a set of detailed classifications. This
work led us to several interesting dependability research questions, and was
the main source of my DC-bug taxonomy work.

\subsection{DC Bug Taxonomy} 

While there have been many LC-bug studies, I am not aware of any large-scale
study of DC bugs. A recent study from Microsoft analyzed the effect of
distributed concurrency on workload and only studied five DC bugs in MapReduce
systems \footnote{Tian Xiao, Jiaxing Zhang, Hucheng Zhou, Zhenyu Guo, Sean
McDirmid, Wei Lin, Wenguang Chen, and Lidong Zhou. Nondeterminism in MapReduce
Considered Harmful?  An Empirical Study on Non-commutative Aggregators in
MapReduce Programs. ICSE '14}. To fill the void, I as one of the project
leaders, have created the largest and most comprehensive taxonomy of 104
real-world DC bugs (named \taxdc) from Cassandra, HBase, Hadoop MapReduce/Yarn,
and ZooKeeper \cite{Gunawi+16-TaxDc-Appear}. \taxdc\ contains in-depth
characteristics of DC bugs, stored in the form of 2,083 classification labels
and 4,528 lines of re-enumerated steps to the bugs that I manually added.
Motivated by the availability of bug benchmarks for LC bugs, I will release
\taxdc\ as a large-scale DC bugs benchmark.

With \taxdc\, I can answer important questions such as: How often are DC bugs 
reported from real deployments? What types of DC bugs exist in real world?
What are the root causes of DC bugs (out-of-order messages, failures, \etc)?
Are existing LC-bug-detection tools applicable for DC bugs? How do developers
fix DC bugs (by adding locks, states, \etc)? What are the inputs/triggering
conditions?  What are the minimum number of distributed events needed to
trigger the bugs (how many messages to re-order, failures to inject, \etc)?
What errors/effects (specification violations) are caused by DC bugs (deadlock,
data loss, state inconsistency, performance problems, \etc)? How do propagation
chains form from the root causes to errors? The answers to these questions will
guide my subsequent research projects.

\section{Distributed System Model Checking}

One powerful method for discovering hidden DC bugs is the use of an
\textit{implementation-level distributed system model checker} (\textbf{dmck}).
By re-ordering non-deterministic distributed events, a dmck can discover buggy
interleavings that lead to DC bugs. The last eight years have seen a rise of
dmcks such as MaceMC \footnote{Charles Killian, James Anderson, Ranjit Jhala,
and Amin Vahdat. Life, Death, and the Critical Transition: Finding Liveness Bugs
in Systems Code. NSDI '07}, \modist\ \footnote{Junfeng Yang, Tisheng Chen, Ming
Wu, Zhilei Xu, Xuezheng Liu, Haoxiang Lin, Mao Yang, Fan Long, Lintao Zhang, and
Lidong Zhou. MODIST: Transparent Model Checking of Unmodified Distributed
Systems. NSDI '09}, or Demeter \footnote{Huayang Guo, Ming Wu, Lidong Zhou, Gang
Hu, Junfeng Yang, and Lintao Zhang. Practical Software Model Checking via
Dynamic Interface Reduction. SOSP '11}. One big challenge faced by a dmck is the
state-space explosion problem (\ie, there are too many distributed events to
re-order). To address this, existing dmcks adopt a random walk or basic
reduction techniques such as dynamic partial order reduction (DPOR). Despite
these early successes, existing approaches cannot unearth many real-world DC
bugs, so I am advancing the state of the art of dmck to combat DC bugs, which I
describe below.

\subsection{Semantic-Aware Model Checking (Initial Work)} 

I started my work by specifically addressing two limitations of existing dmcks.
First, existing dmcks treat every target system as a complete \textit{black
box}, and therefore perform unnecessary reorderings of distributed events that
would lead to the same explored states (\ie, redundant executions). Second,
they do not incorporate complex multiple fault events (\eg, crashes, reboots)
into their exploration strategies, as such inclusion would exacerbate the
state-space explosion problem.

To address these limitations, I built Semantic-Aware Model Checking
(\textbf{SAMC}) \cite{Leesatapornwongsa+15-SamcIssta,Leesatapornwongsa+14-Samc},
a novel white-box model checking approach that takes \textit{semantic knowledge}
of how distributed events (specifically, messages, crashes, and reboots) are
processed by the target system and incorporates that information in reduction
policies.  The policies are based on sound reduction techniques such as DPOR and
symmetry.  The policies tell SAMC not to re-order some pairs of events such as
message-message pairs or crash-message pairs, yet preserves soundness, because
those cut out re-orderings are redundant.

I built SAMC from scratch with 10 KLOC and I was able to reproduce 12 old bugs
in 3 cloud systems involving 30-120 distributed events and multiple crashes and
reboots. Some of these bugs cannot be unearthed by non-SAMC approaches, even
after two days. SAMC can find the bugs up to 271x (33x on average) faster
compared to state-of-the-art techniques. Additionally, I found two new bugs in
Hadoop MapReduce and ZooKeeper.

\subsection{Full Semantic-Aware Model Checking (Ongoing Work)} 

There are two major gaps between existing dmcks (including SAMC) and real-world
DC bugs. First, dmcks reorder messages by default, but they do not control the
timings of all types of events necessary to unearth DC bugs. For example, MaceMC
and SAMC do not intercept local computation and do not exercise timeouts;
\modist\ and Demeter do not inject multiple crash and reboot timings; and none
of the above include other faults such as untimely disk faults.

Second, controlling all necessary events is technically doable, but it will
``blow up'' the exploration space. The use of semantic relationships between
multiple events such as message-message and crash-message semantics in SAMC can
remove redundant re-orderings. However, more innovations are needed to devise
fast exploration strategies that leverage semantic relationships among all
necessary events.

To address the incompleteness of SAMC, I am building \fullcheck, a dmck that
intercepts all types of necessary events to unearth real-world DC bugs, but will
do so in a fast and scalable manner. \fullcheck\ will adopt more advanced
reduction techniques assisted by the incorporation of semantic relationships
between the events. For example, bounded model checking is a popular technique,
which explores only limited depth of distributed events to avoid state-space
explosion, could be useful for dmck, but integration must be done in a wise
manner, because it works well for bugs hiding in early steps of execution only.
Previous works from Microsoft showed that bounded model checking can work with
LC-bug model checking effectively by introducing \textit{iterative context
bounding} \footnote{Madan Musuvathi, and Shaz Qadeer. Iterative Context Bounding
for Systematic Testing of Multithreaded Programs. PLDI '07} and \textit{bounded
partial-order reduction} \footnote{Katherine E. Coons, Madanlal Musuvathi, and
Kathryn S. McKinley. Bounded Partial-Order Reduction. OOPSLA '13}. For dmck, to
effectively integrate bounded model checking, we need a subtle strategy to make
sure that we still explore deep enough to reach hidden bugs.

More reduction techniques are needed, but the semantic-awareness is still the
most important. Demeter, the latest state of the art for exercising
message-computation race, still hits a scalability wall and the authors hint
that using semantic knowledge is an important future direction. I will build
more powerful semantic-awareness principles while adopting new reduction
techniques in the building of \fullcheck.

% I could talk about other reduction technique here, maybe Demeter, bounded
% model checking from MSR, etc.

\subsection{Automated Semantic-Aware Model Checking (Ongoing Work)} 

So far, as we leverage domain-specific semantic information into reduction
strategies, we (or the developers) must manually extract and incorporate the
semantic knowledge and write the corresponding reduction policies. This manual
process, based on high-level human understanding of the codebase, can
potentially miss important patterns due to human errors and breaks soundness.

To address the unsoundness of SAMC and the developers' burden in manually
writing semantic-based reduction strategies, I am creating \autocheck, a dmck
that automatically and soundly extracts complete semantic knowledge into
reduction strategies with the help of program analysis. To do so, I combine
symbolic execution and dmck. While others have used symbolic execution with
model checking for LC bugs, \autocheck\ will be the first case for
implementation-level dmck. 

\subsection{Deep Semantic-Aware Model Checking (Future Work)}

Execution paths to DC bugs often require complex input preconditions such as
multiple faults, reboots, and protocol initiations. I found that more than 60\%
of DC bugs require more than one protocol initiation, 35\% require multiple
faults, and 29\% of DC bugs arise within buggy interactions between foreground
and background protocols.  This again highlights the complexity of complete
systems. If we do not include the complex preconditions, the bugs will not
surface in checking process.

To address this complexity, I will construct \deepcheck, a dmck with a backward
static analysis tool that is capable of searching the necessary input
preconditions to cover unreachable paths. The concept of \deepcheck\ is the dmck
will run with a limited input precondition. Then, \deepcheck\ will analyze which
code path is not reachable given the limited input. It will perform a backward
analysis to search for input preconditions to the path. As a result, this
backward analysis will provide the sequence of input preconditions that cover
more complex scenarios.

\input{bib}

\end{document}
