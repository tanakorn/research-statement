
\documentclass[10pt]{article}

\input{macro}

\usepackage{titling}

\usepackage{times}

\usepackage{setspace}
%\doublespacing

\usepackage[multiple]{footmisc}

\setlength{\droptitle}{-5.5em} 

\setlength{\topmargin}{-.6in} 
\setlength{\textheight}{9in}
\setlength{\textwidth}{7in} 
\setlength{\headheight}{26pt}
\setlength{\headsep}{9pt} 
\setlength{\oddsidemargin}{-.26in}
\setlength{\evensidemargin}{.25in}

\renewcommand{\footnotesize}{\scriptsize}

\begin{document}

\title{\textbf{Research Statement}}
\author{Tanakorn Leesatapornwongsa}
\date{\vspace{-1ex} \small{Department of Computer Science, University of
Chicago}}

\maketitle

My research focuses on improving the dependability of cloud-scale distributed
systems such as scale-out storage systems and distributed computing frameworks.
These distributed systems are back ends of many cloud services, which the
services are expected to be 24/7 dependable. Unfulfilled dependability is
costly, which cloud service companies collectively lose billions of dollars in
revenue each year from service downtimes, yet there are many challenges to reach
an ideal dependability. It is challenging, because the cloud back ends are
complex, they are written in millions of lines of code that are brittle and
prone to failures.

The main focus of my dependability research is on the problem of
\textbf{\textit{distributed concurrency bugs (DC bugs)}}. DC bugs are caused by
nondeterministic orders of distributed events such as message arrivals, hardware
crashes, and reboots. Cloud systems execute multiple complicated distributed
protocols concurrently (\eg, serving users' requests, operating background
tasks, and combined with untimely hardware failures), and possible interleavings
of the distributed events are beyond developers' anticipation, which some
interleavings might not be handled properly, and can cause catastrophic failures
such as data loss and downtimes.

Below I describe how I address the important and challenging problem of DC bugs,
specifically by (1) \textit{performing} an in-depth study of more than 100
real-world DC bugs and (2) \textit{advancing} the state of the art of model
checking for distributed systems. I also will describe my works on other aspects
of cloud dependability.

\section{Distributed Concurrency Bugs (DC Bugs)}\label{dcbugs}

%To combat DC bugs, I establish my research in (1) \textbf{\textit{formal bug
%studies}} and (2) \textbf{\textit{distributed system model checking}}. 

\subsection{DC Bug Study \& Taxonomy} 

Bug and failure studies can significantly guide many aspects of dependability
research. Many researchers have recently employed formal studies on bugs and
failures such as the studies on large-scale system bugs/failures from
Microsoft.\footnote{Guo et al. Failure
Recovery: When the Cure Is Worse Than the Disease. HotOS '13}\footnote{Li et al.
A Characteristic Study On Failures of Production Distributed Data-Parallel
Programs. ICSE '13}
%
However, I am not aware of any large-scale DC-bug study, a recent study from
Microsoft analyzed the effect of distributed concurrency of workload and only
studied five DC bugs in MapReduce.\footnote{Xiao et al.
Nondeterminism in MapReduce Considered Harmful? An Empirical Study on
Non-commutative Aggregators in MapReduce Programs. ICSE '14}

To fill the void, I as one of the project leaders, created the first largest
taxonomy of 104 real-world DC bugs (named \taxdc)
\cite{Leesatapornwongsa+16-TaxDC} from four popular large-scale distributed
systems: Cassandra, HBase, Hadoop MapReduce/Yarn, and ZooKeeper.  \taxdc\
contains in-depth characteristics of DC bugs, stored in the form of 2,083
classification labels and 4,528 lines of re-enumerated steps to the bugs that
we manually added. We show that although DC bugs are complex, but they can be
abstracted and categorized with our taxonomy that covers all aspects of DC bugs
such as bug triggering, errors and failures, and bug fixing.

%\taxdc\ is the most comprehensive taxonomy that covers all aspects of DC bugs
%such as bug triggering, errors and failures, and bug fixing.

%Although DC bugs are complex, we can abstract and categorize them with our
%taxonomy that cover all aspects such as bug triggering, errors and failures, and
%bug fixing.
%
%\taxdc\ contains in-depth characteristics of DC bugs, stored in the form of 2083
%classification labels and 4528 lines of re-enumerated steps to the bugs that we
%manually added. Since we released \taxdc\ as a large-scale DC bugs benchmark,
%it has been downloaded from many research groups including academia and
%industries.

%Motivated by the availability of bug benchmarks for LC bugs, I release \taxdc\
%as a large-scale DC bugs benchmark.

With \taxdc, I can answer important questions such as: 
%
What are the root causes of DC bugs?
%
What are the inputs/triggering conditions? 
%
What errors/effects are caused by DC bugs?
%
How do developers fix DC bugs? 
%
By able to answer these questions, we made \textit{six} major findings that can
spur exciting research topics on DC bug combating, for example, 
%
how to build fast model checker that controls timings of all distributed events, 
%
how state-of-the-art bug detection techniques applicable to DC bugs, 
%
how distributed systems facilitate failure diagnosis, 
%
and how DC-bug-induced failure can be prevented at runtime.
%
We release \taxdc\ as a large-scale DC-bug benchmark, and so far it has been
downloaded from more than \textit{twenty} research groups including academia
and industry, and I believe \taxdc\ will help shape the future research on DC
bugs.

%In addition to the taxonomy, we made six major findings that can 

%Are existing concurrency-bug-detection tools applicable for DC bugs? 
%The answers to these questions will guide my subsequent research projects.

\subsection{Distributed System Model Checking}

One powerful method for discovering hidden DC bugs is the use of an
\textit{implementation-level distributed system model checker} (\textbf{dmck}).
A dmck can discover buggy interleavings that lead to DC bugs by reordering
every possibility of nondeterministic distributed events. The last ten years
have seen a rise of dmcks such as 
%
MaceMC\footnote{Killian et al.
Life, Death, and the Critical Transition: Finding Liveness Bugs
in Systems Code. NSDI '07}, 
%
\modist\footnote{Yang et al.
MODIST: Transparent Model Checking of Unmodified Distributed
Systems. NSDI '09}, or Demeter.\footnote{Guo et al.
Practical Software Model Checking via
Dynamic Interface Reduction. SOSP '11} One big challenge faced by a dmck is the
state-space explosion problem (\ie, there are too many distributed events to
re-order). To address this, existing dmcks adopt a random walk or basic
reduction techniques such as dynamic partial order reduction (DPOR). Despite
these early successes, existing approaches cannot unearth many real-world DC
bugs, so I am advancing the state of the art of dmck to combat DC bugs, which I
describe below.

\subsubsection*{Semantic-Aware Model Checking (Initial Work)} 

I started my work by specifically addressing two limitations of existing dmcks.
First, existing dmcks treat every target system as a complete \textit{black
box}, and perform unnecessary reorderings of distributed events that would lead
to the same states (\ie, redundant executions). Second, they do not incorporate
complex multiple fault events (\eg, crashes, reboots, \etc) into their exploration
strategies, as such inclusion would exacerbate the state-space explosion
problem.

To address these limitations, I built Semantic-Aware Model Checking
(\textbf{SAMC}) \cite{Leesatapornwongsa+15-SamcIssta,Leesatapornwongsa+14-Samc},
a novel white-box model checking approach that takes \textit{semantic knowledge}
of how distributed events (specifically, messages, crashes, and reboots) are
processed by the target system and incorporates that to create reduction
policies. The policies are based on sound reduction techniques such as DPOR and
symmetry. The policies tell SAMC not to re-order some pairs of events such as
message-message pairs, and message-crash pairs, yet preserves soundness, because
those cut out re-orderings are redundant, and unnecessary to check.

I built SAMC from scratch with 10 KLOC, and I was able to reproduce 12 old bugs
in 3 cloud systems (Cassandra, Hadoop MapReduce, and ZooKeeper) involving
30-120 distributed events and multiple crashes and reboots. Some of these bugs
cannot be unearthed by non-SAMC approaches, even after two days. SAMC can find
the bugs up to 271x (33x on average) faster compared to state-of-the-art
techniques, it found two new bugs in Hadoop MapReduce and ZooKeeper, and some
research groups and companies show an interest in adopting SAMC to test their
in-development systems. In addition, although SAMC was introduced under
distributed system context, the principles of \textbf{semantic awareness} I
introduced are also applicable to multithreading software model chekers as
well.

\subsubsection*{Full Semantic-Aware Model Checking (Ongoing Work)} 

Although SAMC advances state of the art of dmcks to unearth DC bugs faster, but
I find that there are two major gaps between existing dmcks (including SAMC) and
real-world DC bugs. First, dmcks reorder messages by default, but they do not
control the timings of all events necessary for DC bugs. For example, MaceMC and
SAMC do not intercept local computation and do not exercise timeouts; \modist\
and Demeter do not inject multiple crash and reboot timings; and none of the
above include other faults such as untimely disk faults.
%
Second, controlling all necessary events is technically doable, but will ``blow
up'' the state space. Thus more innovations are needed to devise fast
exploration strategies that leverage semantic relationships among all necessary
events.

%that leverage semantic relationships among all necessary events.

To address the incompleteness of SAMC, I am building \fullcheck, a dmck that
intercepts all types of necessary events to unearth real-world DC bugs, but will
do so in a fast and scalable manner. Demeter, the latest state of the art for
exercising message-computation race, still hits a scalability wall, and the
authors hint that using semantic knowledge is an important future direction. I
will build more powerful semantic-awareness principles while adopting new
reduction techniques in the building of \fullcheck. \fullcheck\ will be the
first dmck that controls all distributed events necessary to catch DC bugs.

%There are many works from Microsoft on
%model checking for multithreading software to tackle state-space
%explosion\footnote{Madan Musuvathi, and Shaz Qadeer. Iterative Context Bounding
%for Systematic Testing of Multithreaded Programs. PLDI '07}\footnote{Katherine
%E. Coons, Madanlal Musuvathi, and Kathryn S. McKinley. Bounded Partial-Order
%Reduction. OOPSLA '13}, but there are not many works on dmcks, thus I am
%inventing more reduction techniques for dmcks in \fullcheck. 
%Techniques are also assisted by the incorporation of semantic relationships
%between the events. 

%More reduction techniques are needed, but the semantic-awareness is still the
%most important part. Demeter, the latest state of the art for exercising
%message-computation race, still hits a scalability wall, and the authors hint
%that using semantic knowledge is an important future direction. I will build
%more powerful semantic-awareness principles while adopting new reduction
%techniques in the building of \fullcheck. \fullcheck\ will be the first dmck
%that controls all distributed events necessary to catch DC bugs.

%For example, bounded model checking is a popular technique,
%which explores only limited depth of distributed events to avoid state-space
%explosion, could be useful for dmck, but integration must be done in a wise
%manner, because it works well for bugs hiding in early steps of execution only.
%Previous works from Microsoft showed that bounded model checking can work with
%LC-bug model checking effectively by introducing \textit{iterative context
%bounding} \footnote{Madan Musuvathi, and Shaz Qadeer. Iterative Context Bounding
%for Systematic Testing of Multithreaded Programs. PLDI '07} and \textit{bounded
%partial-order reduction} \footnote{Katherine E. Coons, Madanlal Musuvathi, and
%Kathryn S. McKinley. Bounded Partial-Order Reduction. OOPSLA '13}. For dmck, to
%effectively integrate bounded model checking, we need a subtle strategy to make
%sure that we still explore deep enough to reach hidden bugs.

%Demeter, the latest state of the art for exercising message-computation race,
%still hits a scalability wall and the authors hint that using semantic knowledge
%is an important future direction. To address the problem, I am building
%\fullcheck, a dmck that intercepts all necessary events to unearth real-world DC
%bugs, but will do so in a fast and scalable manner. I am inventing more powerful
%semantic-awareness principles while adopting new reduction techniques in the
%building of \fullcheck. \fullcheck\ will be the first dmck that
%controls all distributed events to unearth hidden DC bugs.

%\fullcheck\ will adopt more advanced reduction techniques assisted by
%the incorporation of semantic relationships between the events. 

% I could talk about other reduction technique here, maybe Demeter, bounded
% model checking from MSR, etc.

\subsection{Future Work}

\fullcheck\ will help developers unearth hidden DC bugs in a fast manner, but it
still requires manual efforts from developers. My future work will automate the
processes to reduce the developers' burdensome, as I explain next.

\subsubsection*{Automated Semantic Extractor}

So far, developers manually extract and incorporate the semantic knowledge to
SAMC. This process could introduce human errors and breaks soundness. Thus I
plan to advance SAMC to automatically extracts complete semantic knowledge into
reduction strategies with the help of program analysis. To do so, I will adopt
symbolic execution to automate the semantic-aware reduction policy creation.
While others have used symbolic execution with model checking for
multithreading bugs, this work will be the first case for dmck. 

\subsubsection*{Automatic Input Generator}

Execution paths to DC bugs often require complex input conditions such as
multiple faults, reboots, and protocol initiations. TaxDC shows 80\% of DC bugs
require more than one protocol, 35\% require multiple faults, and 29\% arise
because of interactions between foreground and background protocols. This again
highlights the complexity of complete systems. 
If developers do not test the systems with complex input conditions, the bugs
will not surface in a checking process. To address this complexity, I will adopt
static and dynamic analysis to generate the necessary input preconditions to
cover complex test scenarios necessary to catch hidden DC bugs.

\section{Other Work}

Other than DC bugs, I also address other dimensions of cloud dependability that
traditional dependability techniques are not enough to solve. I briefly explain
the other projects here.

%
%I joined a project
%performing the largest bugs study to find ``\textit{what bugs live in the
%cloud?}'' \cite{Gunawi+14-Cbs}.  We studied six popular Apache cloud
%infrastructures. We reviewed in total 21,399 submitted issues within 2011-2014,
%and perform a deep analysis of 3,655 ``\textit{vital}'' issues. This study show
%novel dimensions of bugs that are \textit{specific} to cloud systems only.
%Motivated by the discovery, I have been working in many projects to tackle the
%bugs in the cloud, which I explain below.

%\subsection*{Scalability Bugs}

\noindent
\textbf{Scalability Bug Checking}: Scalability bugs are latent bugs that are
scale-dependent; they only surface in large-scale deployments, but not in
small/medium-scale ones. Their presence jeopardizes systems reliability and
availability at scale. 
%
While others have tackled scalability bugs in data-plane protocols\footnote{Wang et al.
Exalt: Empowering Researchers to Evaluate Large-Scale Storage Systems. NSDI
'14}, I found that scalability bugs can manifest in control protocols as well.
Control-protocol bugs are more disastrous, yet there is no work addresses about
them.
 
To address this problem, I started a pilot work on scalability checking
\cite{Gunawi+17-SCk-Insub,Leesatapornwongsa+17-SCk-InPrep}. I introduced \sck, a
methodology that enables developers to emulate systems at scale to check and
debug scalability bugs in control protocols, which are CPU-intensive computing,
on \textit{one machine}. 
%
With \sck, I can reproduce six scalability bugs in Cassandra, Riak, and
Voldemort, which manifest in large scale only (\eg\ 200-500 machines). 

%\subsection*{Cloud Bug Study}

\noindent
\textbf{Cloud Bug Study}: To build ground knowledge of holistic cloud
dependability, my colleagues and I performed the largest study on bugs in
cloud-scale distirbuted systems \cite{Gunawi+14-Cbs}. We studied six popular
cloud infrastructures including Cassandra, Flume, Hadoop MapReduce, HBase, HDFS,
and ZooKeeper, and reviewed in total 21,399 submitted issues within 2011-2014,
and performed a deep analysis of 3,655 ``\textit{vital}'' issues (\ie, real
issues affecting deployments). The study shows why cloud-scale distributed
systems are not dependable, and indicates novel dimensions of bugs that are
\textit{unique} to cloud systems such as scalability, topology, and
quality-of-services bugs. We released our cloud bug database to the public, and
so far it has been downloaded \textit{more than 100} times.

%Motivated by the discovery, I have been working in many
%projects to tackle the bugs in the cloud, which I explain below.

%\subsection*{Limpware Tolerant Computing}

\noindent
\textbf{Limpware Tolerant Computing}: It is well-known that hardware can fail in
different ways such as corruption, fail stop, and fail partial, but there is one
often-overlooked cause of performance instability:
``\textbf{limpware}'', \textit{limping} hardware whose performance
degrades significantly compared to its specification. There was no works
studied the impact of this overlooked limpware failure, so my colleagues and I
benchmarked five cloud systems (Cassandra, Hadoop, HBase, HDFS, and ZooKeeper)
with limpware injections \cite{Do+13-Limplock}. The result exposes the inability
of today's cloud systems in dealing with limpware. A single limpware can cripple
other healthy nodes, or even worse, a whole cluster. Motivated from this
observation, we introduced a Path-Based Speculative Execution
(\textbf{PBSE}), that helps data-parallel frameworks recover from limping
network interface cards \cite{Suminto+17-PBSE-InPrep}.

%\subsection*{Drill-Ready Cloud} 

\noindent
\textbf{Drill-Ready Cloud}: Faults in real deployments are very complex, and
the real environments are arbitrary (multi datacenters, layers of
virtualization, massive workloads, \etc), but in offline testings, the
environments are much simpler, and the scale of the workloads and injected
faults are often orders of magnitude smaller. From this fact, I believe a
missing piece toward ideal dependability is \textit{online testing}, which we
inject faults to production to test systems in real deployment, so I introduced
``\textbf{failure drill}'', the concepts of how online testing for cloud should
be operated \cite{Leesatapornwongsa+14-Drill-fixed}. The failure drill
addresses how online test can be safe, efficient, usable, and general.

\section{Summary}

I envision the future of cloud services to be ``uninterrupted''. Cloud services
must be accessible anytime and anywhere, with fast and stable performance, and
not lose or corrupt users' data.
%
I am improving dependability of systems by addressing well-known unsolved
problem of DC bugs via model checker, and tackling new dimensions of cloud
dependability that the systems community has not paid attention. A journey
toward the goal is a long road, but I believe my research advances systems
community toward the direction. 

\input{bib}

\end{document}
